{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BCBio import GFF\n",
    "from BCBio.GFF import GFFExaminer\n",
    "examiner = GFFExaminer()\n",
    "\n",
    "from Bio import SeqIO\n",
    "from pprint import pprint\n",
    "import copy \n",
    "import gspread\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables the user must set to run the analysis.\n",
    "\n",
    "`data_dir` folder into which reference files should be loaded prior to analysis,\n",
    "expected structure\n",
    "\n",
    "```bash\n",
    "{data_dir}\n",
    "├── references\n",
    "│   ├── GorGor\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_029281585.1/\n",
    "│   ├── HomSap\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_009914755.1/\n",
    "│   ├── PanPan\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_029289425.1/\n",
    "│   ├── PanTro\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_028858775.1/\n",
    "│   ├── PonAbe\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_028885655.1/\n",
    "│   ├── PonPyg\n",
    "│   │   └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_028885625.1/\n",
    "│   └── SymSyn\n",
    "│       └── ...  # https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_028878055.1/\n",
    "├── work_dir\n",
    "│       └── ...\n",
    "└── AdditionalFile2-SeqClasses.tsv # Download sequence classes file from additional data files\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/Users/kxp5629/proj/Y/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = f\"{data_dir}/work_dir/x_multicopy\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "\n",
    "data = [\n",
    "    {'species':'PanPan',\n",
    "     'data': {'chr_y': \"NC_073273.1\",\n",
    "              'chr_x': \"NC_073272.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029289425.1.gff3\",\n",
    "              'ref': f\"{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.1/GCF_029289425.1_NHGRI_mPanPan1-v1.1-0.1.freeze_pri_genomic.fna\",\n",
    "              'cds': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.1/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PanPan/ncbi_dataset/data/GCF_029289425.1/protein.faa',\n",
    "              }},\n",
    "    {'species':'PanTro',\n",
    "     'data': {'chr_y': \"NC_072422.1\",\n",
    "              'chr_x': \"NC_072421.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028858775.1.gff3\",\n",
    "              'ref':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/GCF_028858775.1_NHGRI_mPanTro3-v1.1-hic.freeze_pri_genomic.fna\",\n",
    "              'rna':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/rna.fna\",\n",
    "              'prot': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/protein.faa\",\n",
    "              'cds': f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/cds_from_genomic.fna\",\n",
    "              'prot':  f\"{data_dir}/references/PanTro/ncbi_dataset/data/GCF_028858775.1/protein.faa\",\n",
    "              \n",
    "              }},\n",
    "    {'species':'HomSap',\n",
    "     'data': {'chr_y': \"NC_060948.1\",\n",
    "              'chr_x': \"NC_060947.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/hg38.gff3\",\n",
    "              'ref': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/GCF_009914755.1_T2T-CHM13v2.0_genomic.fna\",\n",
    "              'cds': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/cds_from_genomic.fna\",\n",
    "              'prot': f\"{data_dir}/references/HomSap/ncbi_dataset/data/GCF_009914755.1/protein.faa\",\n",
    "              }},\n",
    "    {'species':'GorGor',\n",
    "     'data': {'chr_y': \"NC_073248.1\",\n",
    "              'chr_x': \"NC_073247.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_029281585.1.gff3\",\n",
    "              'ref': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.1/GCF_029281585.1_NHGRI_mGorGor1-v1.1-0.2.freeze_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.1/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/GorGor/ncbi_dataset/data/GCF_029281585.1/protein.faa',\n",
    "              }},\n",
    "    {'species':'PonPyg',\n",
    "     'data': {'chr_y': \"NC_072397.1\",\n",
    "              'chr_x': \"NC_072396.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885625.1.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.1/GCF_028885625.1_NHGRI_mPonPyg2-v1.1-hic.freeze_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.1/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonPyg/ncbi_dataset/data/GCF_028885625.1/protein.faa',\n",
    "              }},\n",
    "    {'species':'PonAbe',\n",
    "     'data': {'chr_y': \"NC_072009.1\",\n",
    "              'chr_x': \"NC_072008.1\",\n",
    "              'path_to_annotation_NCBI': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.1/genomic.gff\",\n",
    "              'path_to_annotation_NCBI_chry': f\"{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.1/genomic_chrY.gff\",\n",
    "              'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028885655.1.gff3\",\n",
    "              'ref': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.1/GCF_028885655.1_NHGRI_mPonAbe1-v1.1-hic.freeze_pri_genomic.fna',\n",
    "              'cds': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.1/cds_from_genomic.fna',\n",
    "              'prot': f'{data_dir}/references/PonAbe/ncbi_dataset/data/GCF_028885655.1/protein.faa',\n",
    "              }},    \n",
    "    {'species':'SymSyn',\n",
    "      'data': {'chr_y': \"NC_072448.1\",\n",
    "               'chr_x': \"NC_072447.1\",\n",
    "               'ref': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.1/GCF_028878055.1_NHGRI_mSymSyn1-v1.1-hic.freeze_pri_genomic.fna',\n",
    "               'path_to_annotation_NCBI': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.1/genomic.gff\",\n",
    "               'path_to_annotation_NCBI_chry': f\"{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.1/genomic_chrY.gff\",\n",
    "               'path_to_annotation_CAT': f\"{data_dir}/CAT/consensus_gene_set/GCF_028878055.1.gff3\",\n",
    "               'cds': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.1/cds_from_genomic.fna',\n",
    "               'prot': f'{data_dir}/references/SymSyn/ncbi_dataset/data/GCF_028878055.1/protein.faa',\n",
    "               }},\n",
    "]\n",
    "\n",
    "species_to_sequence_spec = {\n",
    "    'PanPan': 'bonobo',\n",
    "    'PanTro': 'chimpanzee',\n",
    "    'HomSap': 'human',\n",
    "    'GorGor': 'gorilla',\n",
    "    'PonPyg': 'b-orang',\n",
    "    'PonAbe': 's-orang',\n",
    "    'SymSyn': 'siamang'\n",
    "}\n",
    "\n",
    "species_list = [d['species'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset annotation file to only include chromosome X\n",
    "for species in species_list:\n",
    "\n",
    "    annotation_file =  [d for d in data if d['species'] == species][0]['data']['path_to_annotation_NCBI']\n",
    "    annotation_file_x = annotation_file.replace(\".gff\", \"_chrX.gff\")\n",
    "    chr = [d for d in data if d['species'] == species][0]['data']['chr_x']\n",
    "    print(species, annotation_file, chr)\n",
    "\n",
    "    ! cat $annotation_file | grep -v \"#\" | grep -w $chr | sort -k1,1V -k4,4n -k5,5rn -k3,3r - > $annotation_file_x\n",
    "\n",
    "    annotation_file_y = annotation_file.replace(\".gff\", \"_chrY.gff\")\n",
    "    chr = [d for d in data if d['species'] == species][0]['data']['chr_y']\n",
    "    print(species, annotation_file, chr)\n",
    "\n",
    "    ! cat $annotation_file | grep -v \"#\" | grep -w $chr | sort -k1,1V -k4,4n -k5,5rn -k3,3r - > $annotation_file_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chromosome X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs around 20s without extracting the sequence\n",
    "#runs around 1m with extracting the sequence\n",
    "#only collect ID's will extract sequence from cds_from_genomic.fna\n",
    "record_dict = {}\n",
    "\n",
    "for species in species_list:\n",
    "\n",
    "\n",
    "    annotation_file =  [d for d in data if d['species'] == species][0]['data']['path_to_annotation_NCBI'].replace(\".gff\", \"_chrX.gff\")\n",
    "    handle = open(annotation_file)\n",
    "\n",
    "    # pprint.pprint(examiner.parent_child_map(handle))\n",
    "\n",
    "    # assert False\n",
    "\n",
    "    # records = GFF.parse(handle,base_dict=seq_dict)\n",
    "    records = GFF.parse(handle)\n",
    "    for rec in records:\n",
    "        protss = set()\n",
    "        for feature in rec.features:\n",
    "            if feature.type != \"gene\":\n",
    "                continue\n",
    "            if \"description\" in feature.qualifiers:\n",
    "                description = feature.qualifiers[\"description\"][0]\n",
    "\n",
    "                gene_id = feature.id.replace(\"gene-\", \"\")\n",
    "                gene_spec_id = gene_id + \"_\" + species\n",
    "                    \n",
    "                # print(feature.qualifiers)\n",
    "                for subf in feature.sub_features:\n",
    "\n",
    "                    if subf.type == \"mRNA\":\n",
    "                        mrna_id = subf.id.replace(\"rna-\", \"\")\n",
    "                        for subsubf in subf.sub_features:\n",
    "                            if subsubf.type != \"CDS\":\n",
    "                                continue\n",
    "                            # cds_id = subsubf.id.replace(\"cds-\", \"\")\n",
    "                            prot_id = subsubf.qualifiers[\"protein_id\"][0]\n",
    "                            if prot_id in protss:\n",
    "                                continue\n",
    "\n",
    "                            protss.add(prot_id)\n",
    "                            element = {}\n",
    "                            element[\"specie\"] = species\n",
    "                            element[\"name\"] = description\n",
    "                            element[\"id\"] = prot_id\n",
    "                            element[\"mrna_id\"] = mrna_id\n",
    "                            element[\"gene_id\"] = gene_id\n",
    "                            element[\"start\"] = int(subsubf.location.start)\n",
    "                            element[\"end\"] = int(subsubf.location.end)\n",
    "                            element[\"gene_spec_id\"] = gene_spec_id\n",
    "\n",
    "                            # element[\"seq\"] = str(subf.extract(rec.seq))\n",
    "                            if gene_id in record_dict:\n",
    "                                record_dict[gene_id].append(element)\n",
    "                            else:\n",
    "                                record_dict[gene_id] = [element]\n",
    "\n",
    "    handle.close()\n",
    "\n",
    "pprint(record_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read sequence classes for all species\n",
    "seq_class_dicts = {}\n",
    "for species in species_list:\n",
    "\n",
    "    sequence_class_file = f\"{data_dir}/AdditionalFile2-SeqClasses.tsv\"\n",
    "    seq_class_dicts[species] = []\n",
    "    with open(sequence_class_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if line[0] == species_to_sequence_spec[species]:\n",
    "                if line[2] == \"chrX\":\n",
    "                    seq_class_dicts[species].append(line[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dicts = {}\n",
    "\n",
    "for species in species_list:\n",
    "\n",
    "    sequence_file = [d for d in data if d['species'] == species][0]['data']['prot']\n",
    "    sequence_handle = open(sequence_file)\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(sequence_handle, \"fasta\"))\n",
    "\n",
    "    prot_dicts[species] = seq_dict\n",
    "\n",
    "    sequence_handle.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect sequence for each gene\n",
    "for record in record_dict:\n",
    "    \n",
    "    for element in record_dict[record]:\n",
    "        species = element[\"specie\"]\n",
    "        id = element[\"id\"]\n",
    "        name = element[\"name\"]\n",
    "        # for prot in prot_dicts[specie]:\n",
    "        #     print(prot)\n",
    "        #     print(prot_dicts[specie][prot])\n",
    "        #     assert False\n",
    "        prot_sequences = [prot_dicts[species][x] for x in prot_dicts[species] if (id in x )]\n",
    "        if len(prot_sequences) == 0:\n",
    "            print(\"No sequence found\")\n",
    "            print(id)\n",
    "            assert False\n",
    "        seq = str(prot_sequences[0].seq)\n",
    "        if len(seq) > 1:\n",
    "            for prot in prot_sequences:\n",
    "                if len(prot.seq) > len(seq):\n",
    "                    seq = str(prot.seq)\n",
    "\n",
    "        element[\"seq\"] = seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce list of prot sequences to longest sequence per gene\n",
    "gene_record_dict = {}\n",
    "for record in record_dict:\n",
    "    gene_spec_ids = set()\n",
    "    gene_spec_elements = []\n",
    "    \n",
    "    for element in record_dict[record]:\n",
    "        # gene_id = element[\"gene_id\"]\n",
    "        gene_spec_id = element[\"gene_spec_id\"]\n",
    "        \n",
    "        if gene_spec_id not in gene_spec_ids:\n",
    "            gene_spec_elements.append(element)\n",
    "        else:\n",
    "            if len(element[\"seq\"]) > len([x for x in gene_spec_elements if x[\"gene_spec_id\"] == gene_spec_id][0][\"seq\"]):\n",
    "                for el in gene_spec_elements:\n",
    "                    if el[\"gene_spec_id\"] == gene_spec_id:\n",
    "                        el[\"seq\"] = element[\"seq\"]\n",
    "                        break\n",
    "\n",
    "        gene_spec_ids.add(element[\"gene_spec_id\"])\n",
    "    \n",
    "    gene_record_dict[record] = gene_spec_elements\n",
    "\n",
    "# pprint(gene_record_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print one protein file per specie\n",
    "cmd = f\"mkdir -p {work_dir}/protein_extracted_longest\"\n",
    "subprocess.run(cmd, shell=True)\n",
    "for species in species_list:\n",
    "    file = f\"{work_dir}/protein_extracted_longest/{species}.faa\"\n",
    "\n",
    "\n",
    "    species_records = {}\n",
    "    for gene in gene_record_dict:\n",
    "        species_records[gene] = []\n",
    "        for element in gene_record_dict[gene]:\n",
    "            if element[\"specie\"] == species:\n",
    "                species_records[gene].append(element)\n",
    "\n",
    "\n",
    "    with open(file, \"w\") as outfile:\n",
    "        for entry in species_records:\n",
    "            element = species_records[entry]\n",
    "            if len(element) > 1:\n",
    "                print(species)\n",
    "                assert False\n",
    "            if len(element) == 0:\n",
    "                continue\n",
    "            element = element[0]\n",
    "            outfile.write(f\">{element['id']} gene:{element['gene_id']} mrna:{element['mrna_id']} {element['specie']} {element['name']}\\n\")\n",
    "            outfile.write(f\"{element['seq']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make blast db\n",
    "cmd = f\"mkdir -p {work_dir}/protein_extracted_longest/blastdb\"\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "#concat all fasta files\n",
    "cmd = f\"cat {work_dir}/protein_extracted_longest/*.faa \\\n",
    "    > {work_dir}/protein_extracted_longest/blastdb/all_proteins.faa\"\n",
    "# run command\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make blast db\n",
    "cmd = f\"makeblastdb -in {work_dir}/protein_extracted_longest/blastdb/all_proteins.faa \\\n",
    "     -dbtype prot\\\n",
    "     -out {work_dir}/protein_extracted_longest/blastdb/all_proteins\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blast all against DB\n",
    "for s in species_list:\n",
    "    cmd = f\"blastp -query {work_dir}/protein_extracted_longest/{s}.faa \\\n",
    "    -db {work_dir}/protein_extracted_longest/blastdb/all_proteins \\\n",
    "    -out {work_dir}/protein_extracted_longest/{s}.blastp.tsv \\\n",
    "    -outfmt \\\"6 qseqid sseqid pident mismatch gapopen gaps qcovs qcovshsp evalue\\\" \"\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect edges for each protein\n",
    "edges = {}\n",
    "identity = 50\n",
    "coverage = 35\n",
    "score = 0.001 #this is too high at the moment\n",
    "\n",
    "for s in species_list:\n",
    "    file = f\"{work_dir}/protein_extracted_longest/{s}.blastp.tsv\"\n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if float(line[2]) >= identity and int(line[6]) >= coverage and float(line[7]) < score:\n",
    "                if line[0] in edges:\n",
    "                    edges[line[0]].append(line[1])\n",
    "                else:\n",
    "                    edges[line[0]] = [line[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep two way edges\n",
    "edges_2way = []\n",
    "vertices = set()\n",
    "for node_A in edges:\n",
    "    for node_B in edges[node_A]:\n",
    "        if node_B in edges and node_A in edges[node_B]:\n",
    "            tuple = (node_A, node_B)\n",
    "            tuple = sorted(tuple)\n",
    "\n",
    "            if tuple in edges_2way:\n",
    "                continue\n",
    "\n",
    "            edges_2way.append(tuple)\n",
    "            vertices.add(node_A)\n",
    "            vertices.add(node_B)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clusters with transitive clusering\n",
    "clusters = []\n",
    "for edge in edges_2way:\n",
    "    found = False\n",
    "    for cluster in clusters:\n",
    "        if edge[0] in cluster or edge[1] in cluster:\n",
    "            cluster.add(edge[0])\n",
    "            cluster.add(edge[1])\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        clusters.append(set(edge))\n",
    "\n",
    "\n",
    "#merge clusters with common elements\n",
    "merged_clusters = []\n",
    "for cluster in clusters:\n",
    "    found = False\n",
    "    for merged_cluster in merged_clusters:\n",
    "        if len(cluster.intersection(merged_cluster)) > 0:\n",
    "            merged_cluster.update(cluster)\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        merged_clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_to_species = {}\n",
    "\n",
    "for cluster in merged_clusters:\n",
    "\n",
    "    for prot in cluster:\n",
    "        # print(prot)\n",
    "        species = \"\"\n",
    "        for gene in gene_record_dict:\n",
    "            for element in gene_record_dict[gene]:\n",
    "                if element[\"id\"] == prot:\n",
    "                    species = element[\"specie\"]\n",
    "                    prot_to_species[prot] = species\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read blast results into pandas dataframe\n",
    "# columns :species, gene_A, gene_B, identity, coverage, evalue\n",
    "\n",
    "\n",
    "\n",
    "data_frames = {}\n",
    "for species in species_list:\n",
    "    blast_results = pd.DataFrame(columns=[\"gene_A\", \"gene_B\", \"identity\", \"coverage\", \"evalue\"]) \n",
    "    blast_results_list = []\n",
    "    file = f\"{work_dir}/protein_extracted_longest/{species}.blastp.tsv\"\n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            # if float(line[2]) >= identity and int(line[6]) >= coverage and float(line[7]) < score:\n",
    "            blast_results_list.append({\"species\": species, \"gene_A\": line[0], \"gene_B\": line[1], \"identity\": line[2], \"coverage\": line[6], \"evalue\": line[7]})\n",
    "\n",
    "    blast_results = pd.DataFrame(blast_results_list)\n",
    "    data_frames[species] = blast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palindrome_locations_file_path = \"./data/PalindromeLocations.tsv\" #this file is distributed along the code\n",
    "species_trans = {\n",
    "    \"HomSap_x\": \"chm13\"    ,\n",
    "    \"HomSap_y\": \"hg002\"    ,\n",
    "    \"GorGor\": \"mGorGor1\" ,\n",
    "    \"PanTro\": \"mPanTro3\" ,\n",
    "    \"PanPan\": \"mPanPan1\" ,\n",
    "    \"PonAbe\": \"mPonAbe1\" ,\n",
    "    \"PonPyg\": \"mPonPyg2\" ,\n",
    "    \"SymSyn\": \"mSymSyn1\" \n",
    "}\n",
    "palindrome_locations_file = open(palindrome_locations_file_path, \"r\")\n",
    "palindrome_locations = palindrome_locations_file.readlines()\n",
    "palindrome_locations_file.close()\n",
    "chr = \"x\"\n",
    "\n",
    "palindrome_lines_per_species = {}\n",
    "\n",
    "for species in species_list:\n",
    "    palindrome_lines = []\n",
    "    for row in palindrome_locations:\n",
    "        row = row.strip().split(\"\\t\")\n",
    "        if len(row) < 4:\n",
    "            continue\n",
    "        if row[1] != '' and row[1] != 'start':\n",
    "                    \n",
    "            if species == \"HomSap\":\n",
    "                sp = f\"{species}_{chr}\"\n",
    "                species_chr = f\"{species_trans[sp]}.chr{chr.upper()}\"\n",
    "            else:\n",
    "                species_chr = f\"{species_trans[species]}.chr{chr.upper()}\"\n",
    "\n",
    "            if row[0] == species_chr:\n",
    "                palindrome_lines.append([x.replace(',','') for x in row])\n",
    "    palindrome_lines_per_species[species] = palindrome_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"mkdir -p {work_dir}/protein_extracted_longest/clusters_merged\"\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "file = open(f\"{work_dir}/protein_extracted_longest/clusters_merged/clusters.tsv\", \"w\")\n",
    "file_identities = open(f\"{work_dir}/protein_extracted_longest/clusters_merged/clusters_identities.tsv\", \"w\")\n",
    "file_classes = open(f\"{work_dir}/protein_extracted_longest/clusters_merged/clusters_classes.tsv\", \"w\")\n",
    "\n",
    "header = \"id\\tgene_symbol\\tDescription(s)\"\n",
    "for species in species_list:\n",
    "    header += f\"\\t{species}\"\n",
    "\n",
    "print(header, file=file)\n",
    "print(header, file=file_identities)\n",
    "print(header, file=file_classes)\n",
    "\n",
    "counter = 0\n",
    "prot_to_cluster = {}\n",
    "list_of_all_identities = []\n",
    "for cluster in merged_clusters:\n",
    "\n",
    "    cluster_copy = copy.deepcopy(cluster)\n",
    "    counter += 1\n",
    "    species_count = {}\n",
    "    gene_names = set()\n",
    "    gene_symbol = \"\"\n",
    "    report = False\n",
    "    gene_identity_counter_per_species = {}\n",
    "\n",
    "    classes_per_species = {}\n",
    "    for species in species_list:\n",
    "        classes_per_species[species] = {\n",
    "                \"par_counter\" : 0,\n",
    "                \"ampl_counter\" : 0,\n",
    "                \"ancestral_counter\" : 0,\n",
    "                \"palindrome_counter\" : 0\n",
    "        }\n",
    "    \n",
    "\n",
    "    cluster_fasta_file = f\"{work_dir}/protein_extracted_longest/clusters_merged/cluster_{counter}.faa\"\n",
    "    with open(cluster_fasta_file, \"w\") as cluster_outfile:\n",
    "        for prot in cluster:\n",
    "            # print(prot)\n",
    "            species = \"\"\n",
    "            desc = \"\"\n",
    "            for gene in gene_record_dict:\n",
    "                for element in gene_record_dict[gene]:\n",
    "                    if element[\"id\"] == prot:\n",
    "                        gene_names.add(element[\"name\"])\n",
    "                        species = element[\"specie\"]\n",
    "                        # print(element)\n",
    "                        desc = element[\"name\"]\n",
    "                        report_gene = gene\n",
    "\n",
    "                        prot_to_cluster[prot] = counter\n",
    "                        \n",
    "                        if species in species_count:\n",
    "                            report = True\n",
    "                            # species = element\n",
    "                            species_count[species] += 1\n",
    "                        else:\n",
    "                            species_count[species] = 1\n",
    "                        sequence = element[\"seq\"]\n",
    "\n",
    "                        el_start =  element[\"start\"]\n",
    "                        el_end =  element[\"end\"]\n",
    "\n",
    "                        for seq_class in seq_class_dicts[species]:\n",
    "                            class_name = seq_class[3]\n",
    "                            if el_start >= int(seq_class[1]) and el_end <= int(seq_class[2]):\n",
    "\n",
    "                                if seq_class[3] == \"PAR\":\n",
    "                                    classes_per_species[species][\"par_counter\"] += 1\n",
    "                                elif seq_class[3] == \"AMPLICONIC\":\n",
    "                                    classes_per_species[species][\"ampl_counter\"] += 1\n",
    "                                elif seq_class[3] == \"ANCESTRAL\" :\n",
    "                                    classes_per_species[species][\"ancestral_counter\"] += 1\n",
    "                                break\n",
    "                            else:\n",
    "                                #TODO if more than 50% of the sequence is in the class, count it as in the class\n",
    "                                \n",
    "                                if el_start < int(seq_class[1]) and el_end > int(seq_class[1]):\n",
    "                                    if int(seq_class[1]) - el_start > 0.5 * len(sequence):\n",
    "                                        if seq_class[3] == \"PAR\":\n",
    "                                            classes_per_species[species][\"par_counter\"] += 1\n",
    "                                        elif seq_class[3] == \"AMPLICONIC\":\n",
    "                                            classes_per_species[species][\"ampl_counter\"] += 1\n",
    "                                        elif seq_class[3] == \"ANCESTRAL\":\n",
    "                                            classes_per_species[species][\"ancestral_counter\"] += 1\n",
    "                                        break\n",
    "                                if el_start < int(seq_class[2]) and el_end > int(seq_class[2]):\n",
    "                                    if el_end - int(seq_class[2]) > 0.5 * len(sequence):\n",
    "                                        if seq_class[3] == \"PAR\":\n",
    "                                            classes_per_species[species][\"par_counter\"] += 1\n",
    "                                        elif seq_class[3] == \"AMPLICONIC\":\n",
    "                                            classes_per_species[species][\"ampl_counter\"] += 1\n",
    "                                        elif seq_class[3] == \"ANCESTRAL\":\n",
    "                                            classes_per_species[species][\"ancestral_counter\"] += 1\n",
    "                                        break\n",
    "\n",
    "\n",
    "                        for palindrome in palindrome_lines_per_species[species]:\n",
    "                            if el_start >= int(palindrome[1]) and el_end <= int(palindrome[2]):\n",
    "                                if counter == 21:\n",
    "                                    print(palindrome)\n",
    "                                classes_per_species[species][\"palindrome_counter\"] += 1\n",
    "                                break\n",
    "                            else:\n",
    "                                if el_start < int(palindrome[1]) and el_end > int(palindrome[2]):\n",
    "                                    \n",
    "                                    print(f\"start: {el_start} end: {el_end} palindrome: {palindrome[0]} start: {palindrome[1]} end: {palindrome[2]}\")\n",
    "                                    assert False\n",
    "                                if el_start < int(palindrome[1]) and el_end > int(palindrome[2]):\n",
    "                                    print(f\"start: {el_start} end: {el_end} palindrome: {palindrome[0]} start: {palindrome[1]} end: {palindrome[2]}\")\n",
    "                                    assert False\n",
    "\n",
    "                        if element[\"specie\"] == \"HomSap\":\n",
    "                            if gene.startswith(\"LOC\"):\n",
    "                                continue\n",
    "                            gene_symbol = gene\n",
    "                        break\n",
    "            \n",
    "            print(f\">{prot}_gene:{report_gene}_species:{species} description:{desc}\\n{sequence}\", file=cluster_outfile)   \n",
    "            for prot_B in cluster_copy:\n",
    "                if prot == prot_B:\n",
    "                    continue\n",
    "                species = prot_to_species[prot]\n",
    "                if species != prot_to_species[prot_B]:\n",
    "                    continue\n",
    "                # blast results initiated in later cells, TODO: move to top\n",
    "                blast_results = data_frames[species]\n",
    "                blast_result = blast_results[(blast_results[\"gene_A\"] == prot) & (blast_results[\"gene_B\"] == prot_B)]\n",
    "                if blast_result.empty:\n",
    "                    continue\n",
    "\n",
    "                identity1 = blast_result.iloc[0][\"identity\"]\n",
    "\n",
    "                blast_result = blast_results[(blast_results[\"gene_A\"] == prot_B) & (blast_results[\"gene_B\"] == prot)]\n",
    "                if blast_result.empty:\n",
    "                    continue\n",
    "                identity2 = blast_result.iloc[0][\"identity\"]\n",
    "\n",
    "                if identity2 < identity1:\n",
    "                    identity1 = identity2\n",
    "                if species not in gene_identity_counter_per_species:\n",
    "                    gene_identity_counter_per_species[species] = f\"{identity1}\"\n",
    "                else:\n",
    "                    gene_identity_counter_per_species[species] += f\";{identity1}\"\n",
    "                list_of_all_identities.append(float(identity1))\n",
    "            cluster_copy.remove(prot)\n",
    "                \n",
    "    if report:\n",
    "        \n",
    "        if gene_symbol == \"\":\n",
    "            gene_symbol = list(gene_names)[0]\n",
    "        line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        for species in species_list:\n",
    "            if species not in species_count:\n",
    "                species_count[species] = 0\n",
    "            line += f\"\\t{species_count[species]}\"\n",
    "\n",
    "        print(line, file=file)\n",
    "\n",
    "        identity_line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        for species in species_list:\n",
    "            if species not in gene_identity_counter_per_species:\n",
    "                gene_identity_counter_per_species[species] = 0\n",
    "            identity_line += f\"\\t{gene_identity_counter_per_species[species]}\"\n",
    "        print(identity_line, file=file_identities)\n",
    "\n",
    "        class_line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        \n",
    "        per_line_class_counter = {\n",
    "            \"par_counter\" : 0 ,\n",
    "            \"ampl_counter\" : 0,\n",
    "            \"ancestral_counter\" : 0,\n",
    "            \"palindrome_counter\" : 0\n",
    "        }\n",
    "        for species in species_list:\n",
    "            par_counter = classes_per_species[species][\"par_counter\"]\n",
    "            per_line_class_counter[\"par_counter\"] += par_counter\n",
    "            ampl_counter = classes_per_species[species][\"ampl_counter\"]\n",
    "            per_line_class_counter[\"ampl_counter\"] += ampl_counter\n",
    "            ancestral_counter = classes_per_species[species][\"ancestral_counter\"]\n",
    "            per_line_class_counter[\"ancestral_counter\"] += ancestral_counter\n",
    "            palindrome_counter = classes_per_species[species][\"palindrome_counter\"]\n",
    "            per_line_class_counter[\"palindrome_counter\"] += palindrome_counter\n",
    "            class_line += f\"\\t{ampl_counter} ({palindrome_counter}) + {ancestral_counter} + {par_counter}\"\n",
    "\n",
    "\n",
    "        class_line += f\"\\t{per_line_class_counter['ampl_counter']} ({per_line_class_counter['palindrome_counter']}) + {per_line_class_counter['ancestral_counter']} + {per_line_class_counter['par_counter']}\"\n",
    "        print(class_line, file=file_classes)\n",
    "     \n",
    "file.close()\n",
    "file_identities.close()\n",
    "file_classes.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs around 20s without extracting the sequence\n",
    "#runs around 1m with extracting the sequence\n",
    "#only collect ID's will extract sequence from cds_from_genomic.fna\n",
    "record_dict = {}\n",
    "\n",
    "for species in species_list:\n",
    "\n",
    "\n",
    "    annotation_file =  [d for d in data if d['species'] == species][0]['data']['path_to_annotation_NCBI'].replace(\".gff\", \"_chrY.gff\")\n",
    "    handle = open(annotation_file)\n",
    "\n",
    "    # pprint.pprint(examiner.parent_child_map(handle))\n",
    "\n",
    "    # assert False\n",
    "\n",
    "    # records = GFF.parse(handle,base_dict=seq_dict)\n",
    "    records = GFF.parse(handle)\n",
    "    for rec in records:\n",
    "        protss = set()\n",
    "        for feature in rec.features:\n",
    "            if feature.type != \"gene\":\n",
    "                continue\n",
    "            if \"description\" in feature.qualifiers:\n",
    "                description = feature.qualifiers[\"description\"][0]\n",
    "\n",
    "                gene_id = feature.id.replace(\"gene-\", \"\")\n",
    "                gene_spec_id = gene_id + \"_\" + species\n",
    "                    \n",
    "                # print(feature.qualifiers)\n",
    "                for subf in feature.sub_features:\n",
    "\n",
    "                    if subf.type == \"mRNA\":\n",
    "                        mrna_id = subf.id.replace(\"rna-\", \"\")\n",
    "                        for subsubf in subf.sub_features:\n",
    "                            if subsubf.type != \"CDS\":\n",
    "                                continue\n",
    "                            # cds_id = subsubf.id.replace(\"cds-\", \"\")\n",
    "                            prot_id = subsubf.qualifiers[\"protein_id\"][0]\n",
    "                            if prot_id in protss:\n",
    "                                continue\n",
    "\n",
    "                            protss.add(prot_id)\n",
    "                            element = {}\n",
    "                            element[\"specie\"] = species\n",
    "                            element[\"name\"] = description\n",
    "                            element[\"id\"] = prot_id\n",
    "                            element[\"mrna_id\"] = mrna_id\n",
    "                            element[\"gene_id\"] = gene_id\n",
    "                            element[\"start\"] = int(subsubf.location.start)\n",
    "                            element[\"end\"] = int(subsubf.location.end)\n",
    "                            element[\"gene_spec_id\"] = gene_spec_id\n",
    "\n",
    "                            # element[\"seq\"] = str(subf.extract(rec.seq))\n",
    "                            if gene_id in record_dict:\n",
    "                                record_dict[gene_id].append(element)\n",
    "                            else:\n",
    "                                record_dict[gene_id] = [element]\n",
    "\n",
    "    handle.close()\n",
    "\n",
    "pprint(record_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read sequence classes for all species\n",
    "#read sequence classes for all species\n",
    "seq_class_dicts = {}\n",
    "for species in species_list:\n",
    "\n",
    "    sequence_class_file = f\"{data_dir}/AdditionalFile2-SeqClasses.tsv\"\n",
    "    seq_class_dicts[species] = []\n",
    "    with open(sequence_class_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if line[0] == species_to_sequence_spec[species]:\n",
    "                if line[2] == \"chrY\":\n",
    "                    seq_class_dicts[species].append(line[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(seq_class_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the cds_from_genomic.fna file\n",
    "prot_dicts = {}\n",
    "\n",
    "for species in species_list:\n",
    "\n",
    "    sequence_file = [d for d in data if d['species'] == species][0]['data']['prot']\n",
    "    sequence_handle = open(sequence_file)\n",
    "    seq_dict = SeqIO.to_dict(SeqIO.parse(sequence_handle, \"fasta\"))\n",
    "\n",
    "    prot_dicts[species] = seq_dict\n",
    "\n",
    "    sequence_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in record_dict:\n",
    "    \n",
    "    for element in record_dict[record]:\n",
    "        species = element[\"specie\"]\n",
    "        id = element[\"id\"]\n",
    "        name = element[\"name\"]\n",
    "        # for prot in prot_dicts[specie]:\n",
    "        #     print(prot)\n",
    "        #     print(prot_dicts[specie][prot])\n",
    "        #     assert False\n",
    "        prot_sequences = [prot_dicts[species][x] for x in prot_dicts[species] if (id in x )]\n",
    "        if len(prot_sequences) == 0:\n",
    "            print(\"No sequence found\")\n",
    "            print(id)\n",
    "            assert False\n",
    "        seq = str(prot_sequences[0].seq)\n",
    "        if len(seq) > 1:\n",
    "            for prot in prot_sequences:\n",
    "                if len(prot.seq) > len(seq):\n",
    "                    seq = str(prot.seq)\n",
    "\n",
    "        element[\"seq\"] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce list of prot sequences to longest sequence per gene\n",
    "gene_record_dict = {}\n",
    "for record in record_dict:\n",
    "    gene_spec_ids = set()\n",
    "    gene_spec_elements = []\n",
    "    \n",
    "    for element in record_dict[record]:\n",
    "        # gene_id = element[\"gene_id\"]\n",
    "        gene_spec_id = element[\"gene_spec_id\"]\n",
    "        \n",
    "        if gene_spec_id not in gene_spec_ids:\n",
    "            gene_spec_elements.append(element)\n",
    "        else:\n",
    "            if len(element[\"seq\"]) > len([x for x in gene_spec_elements if x[\"gene_spec_id\"] == gene_spec_id][0][\"seq\"]):\n",
    "                for el in gene_spec_elements:\n",
    "                    if el[\"gene_spec_id\"] == gene_spec_id:\n",
    "                        el[\"seq\"] = element[\"seq\"]\n",
    "                        break\n",
    "\n",
    "        gene_spec_ids.add(element[\"gene_spec_id\"])\n",
    "    \n",
    "    gene_record_dict[record] = gene_spec_elements\n",
    "\n",
    "pprint(gene_record_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print one protein file per specie\n",
    "for species in species_list:\n",
    "    file = f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/{species}.faa\"\n",
    "\n",
    "\n",
    "    species_records = {}\n",
    "    for gene in gene_record_dict:\n",
    "        species_records[gene] = []\n",
    "        for element in gene_record_dict[gene]:\n",
    "            if element[\"specie\"] == species:\n",
    "                species_records[gene].append(element)\n",
    "\n",
    "\n",
    "    with open(file, \"w\") as outfile:\n",
    "        for entry in species_records:\n",
    "            element = species_records[entry]\n",
    "            if len(element) > 1:\n",
    "                print(species)\n",
    "                assert False\n",
    "            if len(element) == 0:\n",
    "                continue\n",
    "            element = element[0]\n",
    "            outfile.write(f\">{element['id']} gene:{element['gene_id']} mrna:{element['mrna_id']} {element['specie']} {element['name']}\\n\")\n",
    "            outfile.write(f\"{element['seq']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make blast db\n",
    "cmd = f\"mkdir -p {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/blastdb\"\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "#concat all fasta files\n",
    "cmd = f\"cat {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/*.faa \\\n",
    "    > {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/blastdb/all_proteins.faa\"\n",
    "# run command\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make blast db\n",
    "cmd = f\"makeblastdb -in {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/blastdb/all_proteins.faa \\\n",
    "     -dbtype prot\\\n",
    "     -out {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/blastdb/all_proteins\"\n",
    "\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blast all against DB\n",
    "for s in species_list:\n",
    "    cmd = f\"blastp -query {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/{s}.faa \\\n",
    "    -db {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/blastdb/all_proteins \\\n",
    "    -out {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/{s}.blastp.tsv \\\n",
    "    -outfmt \\\"6 qseqid sseqid pident mismatch gapopen gaps qcovs qcovshsp evalue\\\" \"\n",
    "    subprocess.run(cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect edges for each protein\n",
    "edges = {}\n",
    "identity = 50\n",
    "coverage = 35\n",
    "score = 0.001 #this is too high at the moment\n",
    "\n",
    "for s in species_list:\n",
    "    file = f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/{s}.blastp.tsv\"\n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if float(line[2]) >= identity and int(line[6]) >= coverage and float(line[7]) < score:\n",
    "                if line[0] in edges:\n",
    "                    edges[line[0]].append(line[1])\n",
    "                else:\n",
    "                    edges[line[0]] = [line[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep two way edges\n",
    "edges_2way = []\n",
    "vertices = set()\n",
    "for node_A in edges:\n",
    "    for node_B in edges[node_A]:\n",
    "        if node_B in edges and node_A in edges[node_B]:\n",
    "            tuple = (node_A, node_B)\n",
    "            tuple = sorted(tuple)\n",
    "\n",
    "            if tuple in edges_2way:\n",
    "                continue\n",
    "\n",
    "            edges_2way.append(tuple)\n",
    "            vertices.add(node_A)\n",
    "            vertices.add(node_B)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clusters with transitive clusering\n",
    "clusters = []\n",
    "for edge in edges_2way:\n",
    "    found = False\n",
    "    for cluster in clusters:\n",
    "        if edge[0] in cluster or edge[1] in cluster:\n",
    "            cluster.add(edge[0])\n",
    "            cluster.add(edge[1])\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        clusters.append(set(edge))\n",
    "\n",
    "\n",
    "#merge clusters with common elements\n",
    "merged_clusters = []\n",
    "for cluster in clusters:\n",
    "    found = False\n",
    "    for merged_cluster in merged_clusters:\n",
    "        if len(cluster.intersection(merged_cluster)) > 0:\n",
    "            merged_cluster.update(cluster)\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        merged_clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_to_species = {}\n",
    "\n",
    "for cluster in merged_clusters:\n",
    "\n",
    "    for prot in cluster:\n",
    "        # print(prot)\n",
    "        species = \"\"\n",
    "        for gene in gene_record_dict:\n",
    "            for element in gene_record_dict[gene]:\n",
    "                if element[\"id\"] == prot:\n",
    "                    species = element[\"specie\"]\n",
    "                    prot_to_species[prot] = species\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read blast results into pandas dataframe\n",
    "# columns :species, gene_A, gene_B, identity, coverage, evalue\n",
    "\n",
    "\n",
    "\n",
    "data_frames = {}\n",
    "for species in species_list:\n",
    "    blast_results = pd.DataFrame(columns=[\"gene_A\", \"gene_B\", \"identity\", \"coverage\", \"evalue\"]) \n",
    "    blast_results_list = []\n",
    "    file = f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/{species}.blastp.tsv\"\n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            # if float(line[2]) >= identity and int(line[6]) >= coverage and float(line[7]) < score:\n",
    "            blast_results_list.append({\"species\": species, \"gene_A\": line[0], \"gene_B\": line[1], \"identity\": line[2], \"coverage\": line[6], \"evalue\": line[7]})\n",
    "\n",
    "    blast_results = pd.DataFrame(blast_results_list)\n",
    "    data_frames[species] = blast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palindrome_locations_file_path = \"./data/PalindromeLocations.tsv\" #this file is distributed along the code\n",
    "species_trans = {\n",
    "    \"HomSap_x\": \"chm13\"    ,\n",
    "    \"HomSap_y\": \"hg002\"    ,\n",
    "    \"GorGor\": \"mGorGor1\" ,\n",
    "    \"PanTro\": \"mPanTro3\" ,\n",
    "    \"PanPan\": \"mPanPan1\" ,\n",
    "    \"PonAbe\": \"mPonAbe1\" ,\n",
    "    \"PonPyg\": \"mPonPyg2\" ,\n",
    "    \"SymSyn\": \"mSymSyn1\" \n",
    "}\n",
    "palindrome_locations_file = open(palindrome_locations_file_path, \"r\")\n",
    "palindrome_locations = palindrome_locations_file.readlines()\n",
    "palindrome_locations_file.close()\n",
    "chr = \"y\"\n",
    "\n",
    "palindrome_lines_per_species = {}\n",
    "\n",
    "for species in species_list:\n",
    "    palindrome_lines = []\n",
    "    for row in palindrome_locations:\n",
    "        row = row.strip().split(\"\\t\")\n",
    "        if len(row) < 4:\n",
    "            continue\n",
    "        if row[1] != '' and row[1] != 'start':\n",
    "                    \n",
    "            if species == \"HomSap\":\n",
    "                sp = f\"{species}_{chr}\"\n",
    "                species_chr = f\"{species_trans[sp]}.chr{chr.upper()}\"\n",
    "            else:\n",
    "                species_chr = f\"{species_trans[species]}.chr{chr.upper()}\"\n",
    "\n",
    "            if row[0] == species_chr:\n",
    "                palindrome_lines.append([x.replace(',','') for x in row])\n",
    "    palindrome_lines_per_species[species] = palindrome_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(palindrome_lines_per_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"mkdir -p {work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged\"\n",
    "subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "file = open(f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/clusters.tsv\", \"w\")\n",
    "file_identities = open(f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/clusters_identities.tsv\", \"w\")\n",
    "file_classes = open(f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/clusters_classes.tsv\", \"w\")\n",
    "\n",
    "header = \"id\\tgene_symbol\\tDescription(s)\"\n",
    "for species in species_list:\n",
    "    header += f\"\\t{species}\"\n",
    "\n",
    "print(header, file=file)\n",
    "print(header, file=file_identities)\n",
    "print(header, file=file_classes)\n",
    "\n",
    "counter = 0\n",
    "prot_to_cluster = {}\n",
    "list_of_all_identities = []\n",
    "for cluster in merged_clusters:\n",
    "\n",
    "    cluster_copy = copy.deepcopy(cluster)\n",
    "    counter += 1\n",
    "    species_count = {}\n",
    "    gene_names = set()\n",
    "    gene_symbol = \"\"\n",
    "    report = False\n",
    "    gene_identity_counter_per_species = {}\n",
    "\n",
    "    classes_per_species = {}\n",
    "    for species in species_list:\n",
    "        classes_per_species[species] = {\n",
    "                \"par_counter\" : 0,\n",
    "                \"ampl_counter\" : 0,\n",
    "                \"ancestral_counter\" : 0,\n",
    "                \"palindrome_counter\" : 0\n",
    "        }\n",
    "    \n",
    "\n",
    "    cluster_fasta_file = f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/cluster_{counter}.faa\"\n",
    "    with open(cluster_fasta_file, \"w\") as cluster_outfile:\n",
    "        for prot in cluster:\n",
    "            # print(prot)\n",
    "            species = \"\"\n",
    "            desc = \"\"\n",
    "            for gene in gene_record_dict:\n",
    "                for element in gene_record_dict[gene]:\n",
    "                    if element[\"id\"] == prot:\n",
    "                        gene_names.add(element[\"name\"])\n",
    "                        species = element[\"specie\"]\n",
    "                        # print(element)\n",
    "                        desc = element[\"name\"]\n",
    "                        report_gene = gene\n",
    "\n",
    "                        prot_to_cluster[prot] = counter\n",
    "                        \n",
    "                        if species in species_count:\n",
    "                            report = True\n",
    "                            # species = element\n",
    "                            species_count[species] += 1\n",
    "                        else:\n",
    "                            species_count[species] = 1\n",
    "                        sequence = element[\"seq\"]\n",
    "\n",
    "                        el_start =  element[\"start\"]\n",
    "                        el_end =  element[\"end\"]\n",
    "\n",
    "                        for seq_class in seq_class_dicts[species]:\n",
    "                            class_name = seq_class[3]\n",
    "                            if el_start >= int(seq_class[1]) and el_end <= int(seq_class[2]):\n",
    "\n",
    "                                if seq_class[3] == \"PAR\":\n",
    "                                    classes_per_species[species][\"par_counter\"] += 1\n",
    "                                elif seq_class[3] == \"AMPLICONIC\":\n",
    "                                    classes_per_species[species][\"ampl_counter\"] += 1\n",
    "                                elif seq_class[3] == \"ANCESTRAL\":\n",
    "                                    classes_per_species[species][\"ancestral_counter\"] += 1\n",
    "                                break\n",
    "                            else:\n",
    "                                if el_start < int(seq_class[1]) and el_end > int(seq_class[1]):\n",
    "                                    print(f\"start: {el_start} end: {el_end} seq_class: {seq_class[0]} start: {seq_class[1]} end: {seq_class[2]}\")\n",
    "                                    assert False\n",
    "                                if el_start < int(seq_class[2]) and el_end > int(seq_class[2]):\n",
    "                                    print(f\"start: {el_start} end: {el_end} seq_class: {seq_class[0]} start: {seq_class[1]} end: {seq_class[2]}\")\n",
    "                                    assert False\n",
    "\n",
    "\n",
    "                        for palindrome in palindrome_lines_per_species[species]:\n",
    "                            if el_start >= int(palindrome[1]) and el_end <= int(palindrome[2]):\n",
    "                                classes_per_species[species][\"palindrome_counter\"] += 1\n",
    "                                break\n",
    "                            else:\n",
    "                                if el_start < int(palindrome[1]) and el_end > int(palindrome[2]):\n",
    "\n",
    "                                    print(f\"start: {el_start} end: {el_end} palindrome: {palindrome[0]} start: {palindrome[1]} end: {palindrome[2]}\")\n",
    "                                    assert False\n",
    "                                if el_start < int(palindrome[1]) and el_end > int(palindrome[2]):\n",
    "                                    if counter == 245:\n",
    "                                        print(palindrome)\n",
    "                                    print(f\"start: {el_start} end: {el_end} palindrome: {palindrome[0]} start: {palindrome[1]} end: {palindrome[2]}\")\n",
    "                                    assert False\n",
    "\n",
    "                        if element[\"specie\"] == \"HomSap\":\n",
    "                            if gene.startswith(\"LOC\"):\n",
    "                                continue\n",
    "                            gene_symbol = gene\n",
    "                        break\n",
    "            \n",
    "            print(f\">{prot}_gene:{report_gene}_species:{species} description:{desc}\\n{sequence}\", file=cluster_outfile)   \n",
    "            for prot_B in cluster_copy:\n",
    "                if prot == prot_B:\n",
    "                    continue\n",
    "                species = prot_to_species[prot]\n",
    "                if species != prot_to_species[prot_B]:\n",
    "                    continue\n",
    "                # blast results initiated in later cells, TODO: move to top\n",
    "                blast_results = data_frames[species]\n",
    "                blast_result = blast_results[(blast_results[\"gene_A\"] == prot) & (blast_results[\"gene_B\"] == prot_B)]\n",
    "                if blast_result.empty:\n",
    "                    continue\n",
    "\n",
    "                identity1 = blast_result.iloc[0][\"identity\"]\n",
    "\n",
    "                blast_result = blast_results[(blast_results[\"gene_A\"] == prot_B) & (blast_results[\"gene_B\"] == prot)]\n",
    "                if blast_result.empty:\n",
    "                    continue\n",
    "                identity2 = blast_result.iloc[0][\"identity\"]\n",
    "\n",
    "                if identity2 < identity1:\n",
    "                    identity1 = identity2\n",
    "                if species not in gene_identity_counter_per_species:\n",
    "                    gene_identity_counter_per_species[species] = f\"{identity1}\"\n",
    "                else:\n",
    "                    gene_identity_counter_per_species[species] += f\";{identity1}\"\n",
    "                list_of_all_identities.append(float(identity1))\n",
    "            cluster_copy.remove(prot)\n",
    "                \n",
    "    if report:\n",
    "        \n",
    "        if gene_symbol == \"\":\n",
    "            gene_symbol = list(gene_names)[0]\n",
    "        line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        for species in species_list:\n",
    "            if species not in species_count:\n",
    "                species_count[species] = 0\n",
    "            line += f\"\\t{species_count[species]}\"\n",
    "\n",
    "        print(line, file=file)\n",
    "\n",
    "        identity_line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        for species in species_list:\n",
    "            if species not in gene_identity_counter_per_species:\n",
    "                gene_identity_counter_per_species[species] = 0\n",
    "            identity_line += f\"\\t{gene_identity_counter_per_species[species]}\"\n",
    "        print(identity_line, file=file_identities)\n",
    "\n",
    "        class_line = f\"{counter}\\t{gene_symbol}\\t{';'.join(gene_names)}\"\n",
    "        \n",
    "        per_line_class_counter = {\n",
    "            \"par_counter\" : 0 ,\n",
    "            \"ampl_counter\" : 0,\n",
    "            \"ancestral_counter\" : 0,\n",
    "            \"palindrome_counter\" : 0\n",
    "        }\n",
    "        for species in species_list:\n",
    "            par_counter = classes_per_species[species][\"par_counter\"]\n",
    "            per_line_class_counter[\"par_counter\"] += par_counter\n",
    "            ampl_counter = classes_per_species[species][\"ampl_counter\"]\n",
    "            per_line_class_counter[\"ampl_counter\"] += ampl_counter\n",
    "            ancestral_counter = classes_per_species[species][\"ancestral_counter\"]\n",
    "            per_line_class_counter[\"ancestral_counter\"] += ancestral_counter\n",
    "            palindrome_counter = classes_per_species[species][\"palindrome_counter\"]\n",
    "            per_line_class_counter[\"palindrome_counter\"] += palindrome_counter\n",
    "            class_line += f\"\\t{ampl_counter} ({palindrome_counter}) + {ancestral_counter} + {par_counter}\"\n",
    "\n",
    "\n",
    "        class_line += f\"\\t{per_line_class_counter['ampl_counter']} ({per_line_class_counter['palindrome_counter']}) + {per_line_class_counter['ancestral_counter']} + {per_line_class_counter['par_counter']}\"\n",
    "        print(class_line, file=file_classes)\n",
    "     \n",
    "file.close()\n",
    "file_identities.close()\n",
    "file_classes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin list of identities by values 50 to 55, 55 to 60, 60 to 65, 65 to 70, 70 to 75, 75 to 80, 80 to 85, 85 to 90, 90 to 95, 95 to 100\n",
    "# sort list by value\n",
    "# list_of_all_identities.sort()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# print(list_of_all_identities)\n",
    "# make y scale log\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(list_of_all_identities, bins = 50, color = 'skyblue', edgecolor='black', alpha = 0.7)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('Identity', fontsize = 12)\n",
    "plt.ylabel('Count', fontsize = 12)\n",
    "plt.title('Histogram of identities', fontsize = 14)\n",
    "\n",
    "#remove frame and white space around plot\n",
    "sns.despine()\n",
    "# Add a black dashed vertical line at x = 97\n",
    "plt.axvline(x=97, color='black', linestyle='--')\n",
    "\n",
    "plt.savefig(f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/identity_histogram.\")\n",
    "# plt.yscale('log')\n",
    "# plt.savefig(f\"{work_dir.replace('x_multicopy','y_multicopy')}/protein_extracted_longest/clusters_merged/identity_histogram_log.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
